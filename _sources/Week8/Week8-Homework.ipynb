{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18326dac-0542-4d93-b5d6-f1014eee6dc2",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "You can download this Jupyter notebook by clicking the download arrow at the top right, and then choosing the `.ipynb` file.\n",
    "\n",
    "## K-Nearest Neighbors classifier\n",
    "We will study the **cars** dataset from `vega_datasets` using a new model, the **K-Nearest Neighbors classifier**.\n",
    "\n",
    "The K-Nearest Neighbors algorithm is the easiest algorithm in Math 10.  It's very similar to the *instance-based learning* from the *Hands On Machine Learning* book that we read about a few weeks ago.  Here is the algorithm.\n",
    "\n",
    "* Choose a number k.\n",
    "* To make a prediction for a point x, find the k closest points in the dataset, and choose the class which appears most often among those k points.  (A slight alternate is to assign probabilities based on those k points.  For example, if k is 10 and 6 of the nearest points are in class A, 3 in class B, and 1 in class C, then we would estimate that our point has a 0.6 probability of being in class A, a 0.3 probability of being in class B, and a 0.1 probability of being in class C.  If we just want to make a prediction, and not give probabilities, we would predict class A.)\n",
    "\n",
    "References:\n",
    "* [Documentation on scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "* [YouTube video explanation](https://www.youtube.com/watch?v=otolSnbanQk) (Just the first few minutes are relevant to us.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4235b1f",
   "metadata": {},
   "source": [
    "## Starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db319aa-bdc3-4dc9-a324-10cbd3691cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from vega_datasets import data\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb76cb49",
   "metadata": {},
   "source": [
    "We will use a very famous dataset in the field of Machine Learning.  It is about cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad9d2a-2cc9-45b4-8df5-1605dae8e11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = data.cars()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77dcf9-ddfc-4d74-8383-318f986ae55a",
   "metadata": {},
   "source": [
    "We will just use three columns from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1557fb3-2042-4bda-98cd-ee701b91a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_a = \"Weight_in_lbs\"\n",
    "col_b = \"Miles_per_Gallon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c882398-d05f-4d15-b055-261bf769d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = source[[col_a,col_b,\"Origin\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1e8af8-c0e6-4fca-be3b-e3ae628335a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_circle().encode(\n",
    "    x = alt.X(col_a,scale=alt.Scale(zero=False)),\n",
    "    y = alt.Y(col_b,scale=alt.Scale(zero=False)),\n",
    "    color='Origin'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7500ee74-63d6-413d-911b-fe381f9725ec",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "Remove the rows containing at least one NaN value.  (Hint.  The result should contain 398 data points.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03077a-0662-4a22-a725-65a24e42c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8f3d2f-fb8f-4edf-9b2e-1a803bd08f28",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Why is this a natural dataset to use StandardScaler on?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1f5a6-db16-4d54-83f6-1191a4af8941",
   "metadata": {},
   "source": [
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdd1f3a",
   "metadata": {},
   "source": [
    "## Scaling the data\n",
    "We scale the data using `StandardScaler` and we temporarily store that scaled data in `df2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffebb3-154e-45eb-a125-ec6eee05641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df2 = df[[col_a,col_b]]\n",
    "scaler.fit(df2)\n",
    "df2 = scaler.transform(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c323fc0-703f-4761-aa31-4c645b590591",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Put those columns back into `df`.  Overwrite the old data, so there should still be just three columns in `df`.  If you evaluate `df.columns`, you should see `Index(['Weight_in_lbs', 'Miles_per_Gallon', 'Origin'], dtype='object')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff10881-9efc-4250-88c4-84a7237dfe66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ba7d7a",
   "metadata": {},
   "source": [
    "## Plotting the scaled data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d2f62-d96d-416d-8bf4-113c54fe5121",
   "metadata": {},
   "source": [
    "If everything went correctly, the chart should look almost identical, just with different numbers along the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8805738f-bd4d-4b8f-b1b3-8d2b7c3693a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_circle().encode(\n",
    "    x = alt.X(col_a,scale=alt.Scale(zero=False)),\n",
    "    y = alt.Y(col_b,scale=alt.Scale(zero=False)),\n",
    "    color='Origin'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794ec4ff-cc24-4cb4-97cb-6dc650962d05",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Instantiate a new `KNeighborsClassifier` (you'll have to import it and then instantiate it) using `n_neighbors = 1`.  Fit the classifier using our two numerical columns for the input `X`, and using the origin column for the output `y`.  Name the classifier `clf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8aab0c-40f5-453f-9020-60185c4924b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd536277-1083-4224-b287-a8116cf1b4d1",
   "metadata": {},
   "source": [
    "## Using `clf` to make a new prediction column\n",
    "We can now make a new prediction column using that classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acf4e32-924f-45c3-9c72-e1f2219517a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pred1\"] = clf.predict(df[[col_a,col_b]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e0d203",
   "metadata": {},
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb26d2-77b8-404f-8416-2b1bc110ed96",
   "metadata": {},
   "source": [
    "Why does the following \"prediction\" chart look identical?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f9352-17ad-4740-bb45-33f5eba5fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df).mark_circle().encode(\n",
    "    x = alt.X(\"Weight_in_lbs\",scale=alt.Scale(zero=False)),\n",
    "    y = alt.Y(\"Miles_per_Gallon\",scale=alt.Scale(zero=False)),\n",
    "    color='pred1'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7103f5ac-5377-4834-9728-3530ce2e5693",
   "metadata": {},
   "source": [
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58e98e7-8d8d-4a0b-8e5e-22e9928f5363",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "Repeat the steps, starting with where we instantiated the classifier, this time using 10 neighbors.  Then again using 50 neighbors.  Show both plots.  (In your submission of this homework, both plots should appear, so don't delete one of them to make the next one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc1b41-e82d-4c65-97f5-5693b21d29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3b2e0f-7273-4c8a-9ccd-3d81b5500465",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "Recall that a machine learning model with more *variance* is more prone to over-fitting, and a machine learning model with more *bias* is more prone to under-fitting.  For example, *linear regression* is more on the bias side, and a high-degree polynomial regression is more on the *variance* side.  This is what's known as the bias-variance tradeoff.  Do you think the K-Nearest Neighbors algorithm has more *bias* when K is a bigger number or a smaller number?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a00b6e-8bf8-4a36-b115-c54803fee031",
   "metadata": {},
   "source": [
    "**Your answer here**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de84cea-3f31-4ce7-83f5-23218d5dffe3",
   "metadata": {},
   "source": [
    "## Example of predicting with new data\n",
    "Here is an example of getting a prediction and probabilities for a car weighing 2000 pounds and getting 26 miles-per-gallon.  You can ignore the warning that shows up; it's just saying that our input does not include column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd4a16-f3ed-415b-8459-c20e6f1e1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = scaler.transform([[2000,26]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af4550-e6dc-4345-96c9-4043d611a497",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e3dbb",
   "metadata": {},
   "source": [
    "It is more interesting and meaningful to get probabilities rather than just a single prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240bd2b-bc56-4f5d-8851-6af50492cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55717e72-0031-457b-8792-03ca156e9cb3",
   "metadata": {},
   "source": [
    "Those probabilities correspond to these classes (they are listed in the same order).  There is no way to know what probability corresponds to what class without evaluating `clf.classes_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5244e502-702e-48cc-ad12-663f81e4e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
